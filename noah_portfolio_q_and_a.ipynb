{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f621683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš¡ QUICK TEST CELL - Use this to test individual questions after setup\n",
    "# Just change the question below and run this cell to see results instantly\n",
    "\n",
    "def quick_test(question):\n",
    "    \"\"\"Quick test function - run this after setup is complete\"\"\"\n",
    "    try:\n",
    "        if 'chain' not in globals():\n",
    "            return \"âŒ Setup not complete! Run the setup cells first.\"\n",
    "        \n",
    "        result = chain(question)\n",
    "        print(f\"ğŸ¤” Question: {question}\")\n",
    "        print(f\"âœ… Answer: {result['result']}\")\n",
    "        print(f\"ğŸ“š Sources used: {len(result['source_documents'])}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"âŒ Error: {e}\"\n",
    "\n",
    "# Test with this question (you can change it):\n",
    "# quick_test(\"What is Noah's educational background?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e37918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Setting up Noah's Portfolio Q&A System - Lightweight Setup...\n",
      "============================================================\n",
      "âœ… Python version: 3.13.7\n",
      "âœ… Executable: c:\\Users\\ndelacalzada\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\n",
      "âœ… Using correct Python installation\n",
      "âœ… All imports successful\n",
      "âœ… OpenAI API key loaded\n",
      "âœ… All imports successful\n",
      "âœ… OpenAI API key loaded\n",
      "âœ… LLM initialized\n",
      "âœ… Loaded 8 documents\n",
      "\n",
      "ğŸ‰ LIGHTWEIGHT SETUP COMPLETE!\n",
      "âœ… Ready for next steps - no heavy operations performed yet\n",
      "ğŸ’¡ Run the next cell to create the vector database\n",
      "============================================================\n",
      "âœ… LLM initialized\n",
      "âœ… Loaded 8 documents\n",
      "\n",
      "ğŸ‰ LIGHTWEIGHT SETUP COMPLETE!\n",
      "âœ… Ready for next steps - no heavy operations performed yet\n",
      "ğŸ’¡ Run the next cell to create the vector database\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ LIGHTWEIGHT SETUP - Quick imports and basic setup (runs fast!)\n",
    "print(\"ğŸš€ Setting up Noah's Portfolio Q&A System - Lightweight Setup...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    import sys\n",
    "    import os\n",
    "    print(f\"âœ… Python version: {sys.version.split()[0]}\")\n",
    "    print(f\"âœ… Executable: {sys.executable}\")\n",
    "    \n",
    "    # Check if we're using the right Python\n",
    "    if \"WindowsApps\" in sys.executable:\n",
    "        print(\"âš ï¸  WARNING: Using Windows Store Python - may have issues!\")\n",
    "    elif \"Python313\" in sys.executable or \".venv\" in sys.executable:\n",
    "        print(\"âœ… Using correct Python installation\")\n",
    "    \n",
    "    # Import all required packages\n",
    "    from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "    from langchain_community.document_loaders import CSVLoader\n",
    "    from langchain_community.vectorstores import FAISS\n",
    "    from langchain.prompts import PromptTemplate\n",
    "    from langchain.chains import RetrievalQA\n",
    "    from dotenv import load_dotenv\n",
    "    print(\"âœ… All imports successful\")\n",
    "    \n",
    "    # Load environment and API key\n",
    "    load_dotenv()\n",
    "    api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    print(\"âœ… OpenAI API key loaded\")\n",
    "    \n",
    "    # Initialize LLM (lightweight - no API calls yet)\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4\",\n",
    "        temperature=0.1,\n",
    "        openai_api_key=api_key\n",
    "    )\n",
    "    print(\"âœ… LLM initialized\")\n",
    "    \n",
    "    # Load CSV data\n",
    "    loader = CSVLoader(file_path='noah_portfolio.csv', source_column=\"answer\")\n",
    "    data = loader.load()\n",
    "    print(f\"âœ… Loaded {len(data)} documents\")\n",
    "    \n",
    "    print(\"\\nğŸ‰ LIGHTWEIGHT SETUP COMPLETE!\")\n",
    "    print(\"âœ… Ready for next steps - no heavy operations performed yet\")\n",
    "    print(\"ğŸ’¡ Run the next cell to create the vector database\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")\n",
    "    print(\"\\nğŸ”§ Troubleshooting:\")\n",
    "    print(\"1. Make sure you selected the correct Python kernel\")\n",
    "    print(\"2. Check that your OpenAI API key is in the .env file\")\n",
    "    print(\"3. Verify noah_portfolio.csv exists\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7db474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ VECTOR DATABASE CREATION - Run this after the lightweight setup above\n",
    "print(\"ğŸ”§ Creating vector database and Q&A chain...\")\n",
    "print(\"â³ This may take 10-30 seconds...\")\n",
    "\n",
    "try:\n",
    "    # Check if previous setup was completed\n",
    "    if 'data' not in locals():\n",
    "        print(\"âŒ Setup not complete! Run the lightweight setup cell above first.\")\n",
    "    else:\n",
    "        # Create embeddings (this is where it might take time)\n",
    "        openai_embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "        print(\"âœ… Embeddings initialized\")\n",
    "        \n",
    "        # Create vector database (this is the potentially slow part)\n",
    "        vectordb = FAISS.from_documents(documents=data, embedding=openai_embeddings)\n",
    "        retriever = vectordb.as_retriever(score_threshold=0.7)\n",
    "        print(\"âœ… Vector database created\")\n",
    "        \n",
    "        # Create Q&A chain\n",
    "        prompt_template = \"\"\"Given the following context and a question, generate an answer based on this context only.\n",
    "In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
    "If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "QUESTION: {question}\"\"\"\n",
    "\n",
    "        PROMPT = PromptTemplate(\n",
    "            template=prompt_template, \n",
    "            input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "        chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "        \n",
    "        chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=retriever,\n",
    "            input_key=\"query\",\n",
    "            return_source_documents=True,\n",
    "            chain_type_kwargs=chain_type_kwargs\n",
    "        )\n",
    "        print(\"âœ… Q&A chain created\")\n",
    "        \n",
    "        print(\"\\nğŸ‰ SUCCESS! Noah's Q&A System is fully ready!\")\n",
    "        print(\"âœ… You can now run the question cells below!\")\n",
    "        print(\"ğŸ’¡ Or test with: chain('Your question here')\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error during vector database creation: {e}\")\n",
    "    print(\"\\n\udd27 This might be due to:\")\n",
    "    print(\"1. OpenAI API rate limits or network issues\")\n",
    "    print(\"2. Large document set taking time to embed\")\n",
    "    print(\"3. FAISS installation issues\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f972f82d",
   "metadata": {},
   "source": [
    "### Basic working of OpenAI GPT-4 in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34aa70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª BASIC LLM TEST - This cell works independently\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key from environment variables  \n",
    "api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "print(f\"âœ… API key loaded: {api_key[:8]}...\")\n",
    "\n",
    "# Initialize GPT-4 model\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.1,\n",
    "    openai_api_key=api_key\n",
    ")\n",
    "print(\"âœ… LLM initialized successfully!\")\n",
    "print(\"ğŸ’¡ Now you can run the next cells to test the LLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b610123",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m poem = \u001b[43mllm\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mWrite a 4 line poem of my love for samosa\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(poem)\n",
      "\u001b[31mNameError\u001b[39m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "# ğŸ¨ LLM POEM TEST - Run this after the LLM initialization above\n",
    "try:\n",
    "    if 'llm' not in locals():\n",
    "        print(\"âŒ LLM not found! Please run the cell above first.\")\n",
    "    else:\n",
    "        print(\"ğŸ¨ Generating poem...\")\n",
    "        poem = llm.invoke(\"Write a 4 line poem of my love for samosa\")\n",
    "        print(\"âœ… Poem generated:\")\n",
    "        print(poem.content)\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")\n",
    "    print(\"ğŸ’¡ Make sure you ran the LLM initialization cell above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c235a80e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ğŸ“§ LLM EMAIL TEST - Run this after the LLM initialization above\n",
    "try:\n",
    "    if 'llm' not in locals():\n",
    "        print(\"âŒ LLM not found! Please run the LLM initialization cell first.\")\n",
    "    else:\n",
    "        print(\"ğŸ“§ Generating email...\")\n",
    "        essay = llm.invoke(\"write email requesting refund for electronic item\")\n",
    "        print(\"âœ… Email generated:\")\n",
    "        print(essay.content)\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")\n",
    "    print(\"ğŸ’¡ Make sure you ran the LLM initialization cell first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227816a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¦ TUTORIAL IMPORTS - This starts the step-by-step tutorial\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "print(\"âœ… Tutorial imports successful!\")\n",
    "print(\"ğŸ’¡ Now proceed with the CSV loading cell below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765695b5",
   "metadata": {},
   "source": [
    "### Now let's load data from Codebasics FAQ csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c62e35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“„ CSV DATA LOADING - Load Noah's portfolio data\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "import os\n",
    "\n",
    "# Check if CSV file exists\n",
    "if not os.path.exists('noah_portfolio.csv'):\n",
    "    print(\"âŒ noah_portfolio.csv not found in current directory!\")\n",
    "    print(f\"ğŸ“ Current directory: {os.getcwd()}\")\n",
    "    csv_files = [f for f in os.listdir('.') if f.endswith('.csv')]\n",
    "    if csv_files:\n",
    "        print(f\"Available CSV files: {csv_files}\")\n",
    "    else:\n",
    "        print(\"No CSV files found\")\n",
    "else:\n",
    "    loader = CSVLoader(file_path='noah_portfolio.csv', source_column=\"answer\")\n",
    "    # Store the loaded data in the 'data' variable\n",
    "    data = loader.load()\n",
    "    print(f\"âœ… Loaded {len(data)} documents about Noah's background\")\n",
    "    print(\"ğŸ’¡ Data loaded successfully! You can now proceed with embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd45e51",
   "metadata": {},
   "source": [
    "### OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a4de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¤ OPENAI EMBEDDINGS - Create embeddings for the tutorial\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Initialize OpenAI embeddings\n",
    "openai_embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "print(\"âœ… OpenAI embeddings initialized\")\n",
    "\n",
    "# Create a sample embedding to test\n",
    "print(\"ğŸ§ª Testing embeddings with sample query...\")\n",
    "e = openai_embeddings.embed_query(\"What is Noah's Professional Background?\")\n",
    "print(f\"âœ… Embedding created! Length: {len(e)}\")\n",
    "print(\"ğŸ’¡ Embeddings are working! You can now create the vector database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0762eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ EMBEDDING LENGTH - Check the embedding dimensions\n",
    "try:\n",
    "    if 'e' not in locals():\n",
    "        print(\"âŒ Embedding 'e' not found! Run the embeddings cell above first.\")\n",
    "    else:\n",
    "        print(f\"âœ… Embedding length: {len(e)}\")\n",
    "        print(\"ğŸ’¡ OpenAI embeddings typically have 1536 dimensions\")\n",
    "except Exception as error:\n",
    "    print(f\"âŒ Error: {error}\")\n",
    "    print(\"ğŸ’¡ Make sure you ran the embeddings cell above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fab6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” EMBEDDING SAMPLE - Look at first 5 values\n",
    "try:\n",
    "    if 'e' not in locals():\n",
    "        print(\"âŒ Embedding 'e' not found! Run the embeddings cell above first.\")\n",
    "    else:\n",
    "        print(\"âœ… First 5 embedding values:\")\n",
    "        print(e[:5])\n",
    "        print(\"ğŸ’¡ These numbers represent semantic meaning in high-dimensional space\")\n",
    "except Exception as error:\n",
    "    print(f\"âŒ Error: {error}\")\n",
    "    print(\"ğŸ’¡ Make sure you ran the embeddings cell above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e571c0d2",
   "metadata": {},
   "source": [
    "As you can see above, embedding for a sentence \"What is your refund policy\" is a list of numbers. OpenAI's text-embedding-ada-002 model creates high-quality embeddings that capture semantic meaning. Looking at the numbers in this list doesn't give any intuitive understanding of what it is, but just assume that these numbers are capturing the meaning of \"What is your refund policy\". If you are curious to know about embeddings, go to youtube and search \"codebasics word embeddings\" and you will find bunch of videos with simple, intuitive explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc80a28a",
   "metadata": {},
   "source": [
    "### Vector store using FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c706da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ—„ï¸ VECTOR DATABASE - Create FAISS vector store\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "try:\n",
    "    if 'data' not in locals():\n",
    "        print(\"âŒ Data not loaded! Please run the CSV loading cell first.\")\n",
    "    elif 'openai_embeddings' not in locals():\n",
    "        print(\"âŒ Embeddings not initialized! Please run the embeddings cell first.\")\n",
    "    else:\n",
    "        print(\"ğŸ”„ Creating FAISS vector database...\")\n",
    "        print(\"â³ This may take 10-30 seconds for embedding creation...\")\n",
    "        \n",
    "        # Create a FAISS instance for vector database from 'data'\n",
    "        vectordb = FAISS.from_documents(documents=data, embedding=openai_embeddings)\n",
    "        print(\"âœ… Vector database created!\")\n",
    "        \n",
    "        # Create a retriever for querying the vector database\n",
    "        retriever = vectordb.as_retriever(score_threshold=0.7)\n",
    "        print(\"âœ… Retriever created with score threshold 0.7\")\n",
    "        print(\"ğŸ’¡ Vector database is ready! You can now test document retrieval.\")\n",
    "        \n",
    "except Exception as error:\n",
    "    print(f\"âŒ Error creating vector database: {error}\")\n",
    "    print(\"ğŸ’¡ Make sure you ran the CSV loading and embeddings cells first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd58f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” RETRIEVAL TEST - Test the vector database retrieval\n",
    "try:\n",
    "    if 'retriever' not in locals():\n",
    "        print(\"âŒ Retriever not found! Please run the vector database cell above first.\")\n",
    "    else:\n",
    "        print(\"ğŸ” Testing document retrieval...\")\n",
    "        rdocs = retriever.get_relevant_documents(\"What is Noah's educational background?\")\n",
    "        print(f\"âœ… Found {len(rdocs)} relevant documents\")\n",
    "        \n",
    "        # Show the first document as a sample\n",
    "        if rdocs:\n",
    "            print(\"\\nğŸ“„ Sample retrieved document:\")\n",
    "            print(f\"Content preview: {rdocs[0].page_content[:200]}...\")\n",
    "            print(\"ğŸ’¡ Vector retrieval is working! You can now create the Q&A chain.\")\n",
    "        else:\n",
    "            print(\"âš ï¸ No documents found - check your query or data\")\n",
    "            \n",
    "except Exception as error:\n",
    "    print(f\"âŒ Error during retrieval: {error}\")\n",
    "    print(\"ğŸ’¡ Make sure you ran the vector database cell above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf6b257",
   "metadata": {},
   "source": [
    "As you can see above, the retriever that was created using FAISS and OpenAI embeddings is now capable of pulling relevant documents from our original CSV file knowledge store. This is very powerful and it will help us further in our project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bee857",
   "metadata": {},
   "source": [
    "##### Embeddings can be created using HuggingFace too. Also for vector database you can use chromadb as well as shown below. During our experimentation, we found OpenAI embeddings and FAISS to be more appropriate for our use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93d079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: HuggingFace embeddings can also be used\n",
    "# from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "# hf_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-large\")\n",
    "\n",
    "# Alternative vector database: ChromaDB\n",
    "# from langchain.vectorstores import Chroma\n",
    "# vectordb = Chroma.from_documents(data,\n",
    "#                            embedding=openai_embeddings,\n",
    "#                            persist_directory='./chromadb')\n",
    "# vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f3d927",
   "metadata": {},
   "source": [
    "### Create RetrievalQA chain along with prompt template ğŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4842c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â›“ï¸ Q&A CHAIN CREATION - Create the final RetrievalQA chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # Load environment for LLM\n",
    "    load_dotenv()\n",
    "    api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    \n",
    "    # Initialize LLM if not already done\n",
    "    if 'llm' not in locals():\n",
    "        llm = ChatOpenAI(model=\"gpt-4\", temperature=0.1, openai_api_key=api_key)\n",
    "        print(\"âœ… LLM initialized for chain\")\n",
    "    \n",
    "    # Check if retriever exists\n",
    "    if 'retriever' not in locals():\n",
    "        print(\"âŒ Retriever not found! Please run the vector database cells first.\")\n",
    "    else:\n",
    "        # Create the prompt template\n",
    "        prompt_template = \"\"\"Given the following context and a question, generate an answer based on this context only.\n",
    "In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
    "If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "QUESTION: {question}\"\"\"\n",
    "\n",
    "        PROMPT = PromptTemplate(\n",
    "            template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "        chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "        print(\"âœ… Prompt template created\")\n",
    "\n",
    "        # Create the RetrievalQA chain\n",
    "        chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=retriever,\n",
    "            input_key=\"query\",\n",
    "            return_source_documents=True,\n",
    "            chain_type_kwargs=chain_type_kwargs\n",
    "        )\n",
    "        print(\"âœ… Q&A Chain created successfully!\")\n",
    "        print(\"ğŸ‰ Setup complete! You can now ask questions using the cells below!\")\n",
    "        print(\"ğŸ’¡ Or test directly with: chain.invoke('Your question here')\")\n",
    "\n",
    "except Exception as error:\n",
    "    print(f\"âŒ Error creating Q&A chain: {error}\")\n",
    "    print(\"ğŸ’¡ Make sure you ran all the previous tutorial cells in sequence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152a4cf8",
   "metadata": {},
   "source": [
    "### We are all set ğŸ‘ğŸ¼ Let's ask questions about Noah's background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90166e8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/ndelacalzada/AppData/Local/Microsoft/WindowsApps/python3.11.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# âœ… SYSTEM VERIFICATION - Test that the Q&A system is working\n",
    "print(\"ğŸ§ª Testing Noah's Portfolio Q&A System...\")\n",
    "\n",
    "try:\n",
    "    # Check if chain exists\n",
    "    if 'chain' not in locals():\n",
    "        print(\"âŒ Chain not found! Please run the tutorial cells above in sequence:\")\n",
    "        print(\"   1. Import required libraries\")\n",
    "        print(\"   2. Load CSV data\") \n",
    "        print(\"   3. Initialize embeddings\")\n",
    "        print(\"   4. Create vector database\")\n",
    "        print(\"   5. Create Q&A chain\")\n",
    "    else:\n",
    "        print(\"âœ… Chain found! Testing Q&A system...\")\n",
    "        \n",
    "        # Test the system\n",
    "        test_question = \"What is Noah's Professional Background?\"\n",
    "        print(f\"ğŸ¤” Testing with: {test_question}\")\n",
    "        \n",
    "        result = chain.invoke(test_question)\n",
    "        \n",
    "        print(\"\\nğŸ¯ Test Result:\")\n",
    "        print(f\"âœ… Answer: {result['result']}\")\n",
    "        print(f\"ğŸ“š Sources used: {len(result['source_documents'])}\")\n",
    "        \n",
    "        print(\"\\nğŸ‰ System is working perfectly!\")\n",
    "        print(\"ğŸ’¡ You can now ask questions using the cells below!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error during system test: {e}\")\n",
    "    print(\"\\nğŸ”§ Troubleshooting:\")\n",
    "    print(\"1. Make sure to run all tutorial cells above in sequence\")\n",
    "    print(\"2. Check that your OpenAI API key is set correctly\")\n",
    "    print(\"3. Verify that noah_portfolio.csv exists in the directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b848b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” System Diagnostics:\n",
      "Python version: 3.13.7 (tags/v3.13.7:bcee1c3, Aug 14 2025, 14:15:11) [MSC v.1944 64 bit (AMD64)]\n",
      "Python executable: c:\\Users\\ndelacalzada\\Downloads\\langchain-main - Copy\\.venv\\Scripts\\python.exe\n",
      "Current directory: c:\\Users\\ndelacalzada\\Downloads\\langchain-main - Copy\\langchain-main\\3_project_codebasics_q_and_a\n",
      "â„¹ï¸  Using Python from: c:\\Users\\ndelacalzada\\Downloads\\langchain-main - Copy\\.venv\\Scripts\\python.exe\n",
      "âœ… All LangChain imports successful\n",
      "âœ… OpenAI API key loaded and valid format\n",
      "âœ… All LangChain imports successful\n",
      "âœ… OpenAI API key loaded and valid format\n",
      "âœ… OpenAI API connection successful\n",
      "âœ… noah_portfolio.csv found\n",
      "   CSV has 9 lines\n",
      "âœ… FAISS index directory exists\n",
      "\n",
      "ğŸš€ NEXT STEPS:\n",
      "1. If using Windows Store Python, change kernel (see warning above)\n",
      "2. If all checks pass, run cells 3-20 in order to set up the system\n",
      "3. Then test with the question cells at the bottom\n",
      "\n",
      "============================================================\n",
      "KERNEL SELECTION INSTRUCTIONS:\n",
      "1. Look at top-right corner of notebook\n",
      "2. Click on the Python version/kernel name\n",
      "3. Select 'Python 3 (Noah Chatbot)' if available\n",
      "4. Or choose Python 3.13 from Local Programs (NOT WindowsApps)\n",
      "============================================================\n",
      "âœ… OpenAI API connection successful\n",
      "âœ… noah_portfolio.csv found\n",
      "   CSV has 9 lines\n",
      "âœ… FAISS index directory exists\n",
      "\n",
      "ğŸš€ NEXT STEPS:\n",
      "1. If using Windows Store Python, change kernel (see warning above)\n",
      "2. If all checks pass, run cells 3-20 in order to set up the system\n",
      "3. Then test with the question cells at the bottom\n",
      "\n",
      "============================================================\n",
      "KERNEL SELECTION INSTRUCTIONS:\n",
      "1. Look at top-right corner of notebook\n",
      "2. Click on the Python version/kernel name\n",
      "3. Select 'Python 3 (Noah Chatbot)' if available\n",
      "4. Or choose Python 3.13 from Local Programs (NOT WindowsApps)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”§ COMPLETE SYSTEM CHECK AND SETUP\n",
    "# Run this cell first to ensure everything is working properly\n",
    "\n",
    "import sys\n",
    "import os\n",
    "print(\"ğŸ” System Diagnostics:\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Check if we're using the correct Python installation\n",
    "if \"WindowsApps\" in sys.executable:\n",
    "    print(\"âš ï¸  WARNING: You're using Windows Store Python!\")\n",
    "    print(\"   This version may have package installation issues.\")\n",
    "    print(\"   Please select the correct kernel:\")\n",
    "    print(\"   1. Click the kernel selector (top-right of notebook)\")\n",
    "    print(\"   2. Choose 'Python 3 (Noah Chatbot)' or\")\n",
    "    print(\"   3. Select Python 3.13 from Programs/Python/Python313\")\n",
    "    print(\"\")\n",
    "elif \"Python313\" in sys.executable or \"python313\" in sys.executable.lower():\n",
    "    print(\"âœ… Using correct Python 3.13 installation\")\n",
    "else:\n",
    "    print(f\"â„¹ï¸  Using Python from: {sys.executable}\")\n",
    "\n",
    "try:\n",
    "    # Check all imports - UPDATED to use correct imports\n",
    "    from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "    from langchain_community.document_loaders import CSVLoader\n",
    "    from langchain_community.vectorstores import FAISS\n",
    "    from langchain.prompts import PromptTemplate\n",
    "    from langchain.chains import RetrievalQA\n",
    "    from dotenv import load_dotenv\n",
    "    print(\"âœ… All LangChain imports successful\")\n",
    "    \n",
    "    # Load environment variables\n",
    "    load_dotenv()\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    if api_key and api_key.startswith('sk-'):\n",
    "        print(\"âœ… OpenAI API key loaded and valid format\")\n",
    "        # Test a simple API call\n",
    "        try:\n",
    "            llm = ChatOpenAI(model=\"gpt-4\", temperature=0.1, openai_api_key=api_key)\n",
    "            print(\"âœ… OpenAI API connection successful\")\n",
    "        except Exception as api_error:\n",
    "            print(f\"âŒ OpenAI API test failed: {api_error}\")\n",
    "    else:\n",
    "        print(\"âŒ OpenAI API key not found or invalid format\")\n",
    "        \n",
    "    # Check CSV file\n",
    "    if os.path.exists('noah_portfolio.csv'):\n",
    "        print(\"âœ… noah_portfolio.csv found\")\n",
    "        # Check CSV content\n",
    "        with open('noah_portfolio.csv', 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            print(f\"   CSV has {len(lines)} lines\")\n",
    "    else:\n",
    "        print(\"âŒ noah_portfolio.csv not found in current directory\")\n",
    "        csv_files = [f for f in os.listdir('.') if f.endswith('.csv')]\n",
    "        if csv_files:\n",
    "            print(f\"Available CSV files: {csv_files}\")\n",
    "        else:\n",
    "            print(\"No CSV files found\")\n",
    "            \n",
    "    # Check for FAISS index\n",
    "    if os.path.exists('faiss_index'):\n",
    "        print(\"âœ… FAISS index directory exists\")\n",
    "    else:\n",
    "        print(\"â„¹ï¸  FAISS index not found (will be created when needed)\")\n",
    "        \n",
    "    print(\"\\nğŸš€ NEXT STEPS:\")\n",
    "    print(\"1. If using Windows Store Python, change kernel (see warning above)\")\n",
    "    print(\"2. If all checks pass, run cells 3-20 in order to set up the system\")\n",
    "    print(\"3. Then test with the question cells at the bottom\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import error: {e}\")\n",
    "    print(\"\\nğŸ”§ Fix by running in terminal:\")\n",
    "    print(\"pip install langchain-openai langchain-community faiss-cpu python-dotenv\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Unexpected error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KERNEL SELECTION INSTRUCTIONS:\")\n",
    "print(\"1. Look at top-right corner of notebook\")\n",
    "print(\"2. Click on the Python version/kernel name\")\n",
    "print(\"3. Select 'Python 3 (Noah Chatbot)' if available\")\n",
    "print(\"4. Or choose Python 3.13 from Local Programs (NOT WindowsApps)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a4e3e4",
   "metadata": {},
   "source": [
    "**As you can see above, the system can now answer questions about Noah's professional background using the information from the CSV file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dce73e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mchain\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mWhat is Noah\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms Education background?\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'chain' is not defined"
     ]
    }
   ],
   "source": [
    "# ğŸ“ EDUCATION QUESTION - Ask about Noah's educational background\n",
    "try:\n",
    "    if 'chain' not in locals():\n",
    "        print(\"âŒ Q&A system not ready! Please run the setup cells first.\")\n",
    "    else:\n",
    "        question = \"What is Noah's Education background?\"\n",
    "        print(f\"ğŸ¤” Question: {question}\")\n",
    "        \n",
    "        result = chain.invoke(question)\n",
    "        print(f\"\\nâœ… Answer: {result['result']}\")\n",
    "        print(f\"ğŸ“š Sources: {len(result['source_documents'])}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")\n",
    "    print(\"ğŸ’¡ Make sure the Q&A system is set up (run tutorial cells above)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48970302",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ğŸ’¼ SALES EXPERIENCE QUESTION - Ask about Noah's sales work experience\n",
    "try:\n",
    "    if 'chain' not in locals():\n",
    "        print(\"âŒ Q&A system not ready! Please run the setup cells first.\")\n",
    "    else:\n",
    "        question = \"Tell me about Noah's work experience in sales\"\n",
    "        print(f\"ğŸ¤” Question: {question}\")\n",
    "        \n",
    "        result = chain.invoke(question)\n",
    "        print(f\"\\nâœ… Answer: {result['result']}\")\n",
    "        print(f\"ğŸ“š Sources: {len(result['source_documents'])}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")\n",
    "    print(\"ğŸ’¡ Make sure the Q&A system is set up (run tutorial cells above)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17dc6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ† CERTIFICATIONS QUESTION - Ask about Noah's certifications\n",
    "try:\n",
    "    if 'chain' not in locals():\n",
    "        print(\"âŒ Q&A system not ready! Please run the setup cells first.\")\n",
    "    else:\n",
    "        question = \"What certifications does Noah have?\"\n",
    "        print(f\"ğŸ¤” Question: {question}\")\n",
    "        \n",
    "        result = chain.invoke(question)\n",
    "        print(f\"\\nâœ… Answer: {result['result']}\")\n",
    "        print(f\"ğŸ“š Sources: {len(result['source_documents'])}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")\n",
    "    print(\"ğŸ’¡ Make sure the Q&A system is set up (run tutorial cells above)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c35c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ› ï¸ SKILLS QUESTION - Ask about Noah's skills\n",
    "try:\n",
    "    if 'chain' not in locals():\n",
    "        print(\"âŒ Q&A system not ready! Please run the setup cells first.\")\n",
    "    else:\n",
    "        question = \"What skills does Noah have?\"\n",
    "        print(f\"ğŸ¤” Question: {question}\")\n",
    "        \n",
    "        result = chain.invoke(question)\n",
    "        print(f\"\\nâœ… Answer: {result['result']}\")\n",
    "        print(f\"ğŸ“š Sources: {len(result['source_documents'])}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")\n",
    "    print(\"ğŸ’¡ Make sure the Q&A system is set up (run tutorial cells above)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a054c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¢ B2B SALES QUESTION - Ask about Noah's B2B experience\n",
    "try:\n",
    "    if 'chain' not in locals():\n",
    "        print(\"âŒ Q&A system not ready! Please run the setup cells first.\")\n",
    "    else:\n",
    "        question = \"Can you describe Noah's experience in B2B sales?\"\n",
    "        print(f\"ğŸ¤” Question: {question}\")\n",
    "        \n",
    "        result = chain.invoke(question)\n",
    "        print(f\"\\nâœ… Answer: {result['result']}\")\n",
    "        print(f\"ğŸ“š Sources: {len(result['source_documents'])}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")\n",
    "    print(\"ğŸ’¡ Make sure the Q&A system is set up (run tutorial cells above)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fa5d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¬ BIOLOGICAL SCIENCES QUESTION - Ask about Noah's science background\n",
    "try:\n",
    "    if 'chain' not in locals():\n",
    "        print(\"âŒ Q&A system not ready! Please run the setup cells first.\")\n",
    "    else:\n",
    "        question = \"What is Noah's educational background in biological sciences?\"\n",
    "        print(f\"ğŸ¤” Question: {question}\")\n",
    "        \n",
    "        result = chain.invoke(question)\n",
    "        print(f\"\\nâœ… Answer: {result['result']}\")\n",
    "        print(f\"ğŸ“š Sources: {len(result['source_documents'])}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")\n",
    "    print(\"ğŸ’¡ Make sure the Q&A system is set up (run tutorial cells above)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6539e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸŒŸ CANDIDATE EVALUATION QUESTION - Ask about Noah as a sales candidate\n",
    "try:\n",
    "    if 'chain' not in locals():\n",
    "        print(\"âŒ Q&A system not ready! Please run the setup cells first.\")\n",
    "    else:\n",
    "        question = \"How would you describe Noah as a candidate for a sales position?\"\n",
    "        print(f\"ğŸ¤” Question: {question}\")\n",
    "        \n",
    "        result = chain.invoke(question)\n",
    "        print(f\"\\nâœ… Answer: {result['result']}\")\n",
    "        print(f\"ğŸ“š Sources: {len(result['source_documents'])}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")\n",
    "    print(\"ğŸ’¡ Make sure the Q&A system is set up (run tutorial cells above)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Noah Direct Python 3.13",
   "language": "python",
   "name": "noah-direct"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
