# Noah's Portfolio Q&A

An AI-powered Q&A system for Noah's professional portfolio using LangChain, OpenAI, and FAISS with comprehensive analytics tracking.

## âœ¨ Key Features
- **RAG-powered Q&A** - Retrieval-Augmented Generation over curated knowledge base
- **Smart LinkedIn Integration** - Auto-includes professional profile for career questions  
- **Comprehensive Analytics** - SQLite-based tracking of all interactions and performance metrics
- **Professional UI** - Streamlit interface with sidebar controls and analytics dashboard
- **Zero-config Deployment** - Works out of the box with minimal setup
- **Optimized Performance** - Efficient caching and indexed database queries

## ğŸš€ Quick Start

1. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

2. **Set your OpenAI API key**
   ```bash
   export OPENAI_API_KEY="sk-your-key-here"
   ```
   Or create `.streamlit/secrets.toml`:
   ```toml
   OPENAI_API_KEY = "sk-your-key-here"
   ```

3. **Run the application**
   ```bash
   streamlit run main.py
   ```

4. **Initialize knowledge base** - Click "Create / Refresh Index" in the sidebar, then ask questions!

## â˜ï¸ Deploy on Streamlit Cloud

- **App file**: `main.py`
- **Secrets**: Add `OPENAI_API_KEY` in Streamlit Cloud secrets
- **Optional**: Set `HEADSHOT_URL` and `HEADSHOT_NAME` for profile customization

## âš™ï¸ Configuration

All settings can be configured via environment variables or Streamlit secrets:

| Setting | Default | Description |
|---------|---------|-------------|
| `OPENAI_MODEL` | `gpt-4` | OpenAI model for responses |
| `OPENAI_TEMPERATURE` | `0.1` | Response creativity (0.0-1.0) |
| `OPENAI_EMBEDDING_MODEL` | `text-embedding-3-small` | Embedding model |
| `CSV_FILE_PATH` | `noah_portfolio.csv` | Knowledge base file |
| `RETRIEVER_SCORE_THRESHOLD` | `0.7` | Similarity threshold |
| `LINKEDIN_URL` | - | Auto-include for career questions |

## ğŸ“ Project Structure

```
â”œâ”€â”€ main.py                 # Streamlit UI and main application
â”œâ”€â”€ langchain_helper.py     # RAG chain and vector database management
â”œâ”€â”€ analytics.py           # SQLite-based interaction tracking
â”œâ”€â”€ config.py              # Configuration and secrets management
â”œâ”€â”€ noah_portfolio.csv     # Knowledge base (36+ Q&A pairs)
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ faiss_index/           # Vector database (auto-generated)
â””â”€â”€ archive/               # Legacy Flask files (deprecated)
```

## ğŸ“Š Analytics Features

- **Interaction Logging** - All Q&A pairs stored in SQLite
- **Performance Metrics** - Response times and retrieval statistics  
- **Behavioral Analysis** - Career vs general question classification
- **Export Capabilities** - CSV export for external analysis
- **Dashboard View** - Built-in analytics viewer (`analytics_viewer.py`)

## ğŸ› ï¸ Development

**Run tests**:
```bash
python quick_test.py        # Basic functionality check
python test_system.py       # Comprehensive testing
python final_validation.py  # Full system validation
```

**View analytics**:
```bash
streamlit run analytics_viewer.py
```

## ğŸ”§ Troubleshooting

| Issue | Solution |
|-------|----------|
| "OpenAI key present: False" | Set `OPENAI_API_KEY` in secrets or environment |
| Embedding errors | Use default `text-embedding-3-small` model |
| FAISS read error | Click "Create / Refresh Index" to rebuild |
| Import errors | Run `pip install -r requirements.txt` |

## ğŸ“– Documentation

- **[Analytics Guide](ANALYTICS_GUIDE.md)** - Detailed analytics system documentation
- **[Refactoring Summary](REFACTORING_SUMMARY.md)** - Recent improvements and optimizations

## ğŸ”’ Security

- âœ… **No hardcoded secrets** - All API keys via secure configuration
- âœ… **Multi-layer fallback** - Streamlit Secrets â†’ Environment â†’ Local files
- âœ… **Input validation** - Query sanitization and rate limiting
- âœ… **Source attribution** - All responses include traceable references

## ğŸš€ Performance

- **Cold start**: 2-3 seconds (first query)
- **Warm queries**: <500ms (cached resources)
- **Memory usage**: ~200MB including models
- **Scalability**: Supports 10K+ documents with minimal changes

---

**Built with**: LangChain, OpenAI GPT-4, FAISS, Streamlit, SQLite
